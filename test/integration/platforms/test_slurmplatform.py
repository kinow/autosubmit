# Copyright 2015-2025 Earth Sciences Department, BSC-CNS
#
# This file is part of Autosubmit.
#
# Autosubmit is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# Autosubmit is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with Autosubmit.  If not, see <http://www.gnu.org/licenses/>.

"""Integration tests for the Slurm platform.

As these tests use a GitHub Actions service with limited capacity for running jobs,
we limit in pytest how many tests we run in parallel to avoid the service becoming
unresponsive (which likely explains our banner timeout messages before, as probably
it was busy churning the previous messages and Slurm jobs).

This is done by assigning the tests the group "slurm". This forces pytest to send
all the grouped tests to the same worker.
"""

import re
from pathlib import Path
from textwrap import dedent

import pytest

from autosubmit.config.configcommon import AutosubmitConfig
from autosubmit.config.yamlparser import YAMLParserFactory
from autosubmit.history.experiment_history import ExperimentHistory
from autosubmit.job.job import Job
from autosubmit.job.job_common import Status
from autosubmit.job.job_list import JobList
from autosubmit.job.job_list_persistence import JobListPersistencePkl
from autosubmit.job.job_packager import JobPackager
from autosubmit.log.utils import is_gzip_file, is_xz_file
from autosubmit.platforms.paramiko_submitter import ParamikoSubmitter
from autosubmit.platforms.slurmplatform import SlurmPlatform
from test.integration.conftest import AutosubmitExperimentFixture, DockerContainer

_EXPID = 't001'

_PLATFORM_NAME = 'TEST_SLURM'


def _create_slurm_platform(expid: str, as_conf: AutosubmitConfig):
    return SlurmPlatform(expid, _PLATFORM_NAME, config=as_conf.experiment_data, auth_password=None)


@pytest.mark.xdist_group('slurm')
@pytest.mark.slurm
def test_create_platform_slurm(
        autosubmit_exp,
        slurm_server: 'DockerContainer',
):
    """Test the Slurm platform object creation."""
    exp = autosubmit_exp('t000', experiment_data={
        'JOBS': {
            'SIM': {
                'PLATFORM': _PLATFORM_NAME,
                'RUNNING': 'once',
                'SCRIPT': 'echo "This is job ${SLURM_JOB_ID} EOM"',
            }
        },
        'PLATFORMS': {
            _PLATFORM_NAME: {
                'ADD_PROJECT_TO_HOST': False,
                'HOST': '127.0.0.1',
                'MAX_WALLCLOCK': '00:03',
                'PROJECT': 'group',
                'QUEUE': 'gp_debug',
                'SCRATCH_DIR': '/tmp/scratch/',
                'TEMP_DIR': '',
                'TYPE': 'slurm',
                'USER': 'root',
                'MAX_PROCESSORS': 1,
                'PROCESSORS_PER_NODE': 1,
            }
        }
    })
    platform = _create_slurm_platform(exp.expid, exp.as_conf)
    assert platform.name == _PLATFORM_NAME
    # TODO: add more assertion statements...


@pytest.mark.xdist_group('slurm')
@pytest.mark.slurm
@pytest.mark.parametrize('experiment_data', [
    {
        'JOBS': {
            'SIM': {
                'PLATFORM': _PLATFORM_NAME,
                'RUNNING': 'once',
                'SCRIPT': 'echo "This is job ${SLURM_JOB_ID} EOM"',
            },
        },
        'PLATFORMS': {
            _PLATFORM_NAME: {
                'ADD_PROJECT_TO_HOST': False,
                'HOST': '127.0.0.1',
                'MAX_WALLCLOCK': '00:03',
                'PROJECT': 'group',
                'QUEUE': 'gp_debug',
                'SCRATCH_DIR': '/tmp/scratch/',
                'TEMP_DIR': '',
                'TYPE': 'slurm',
                'USER': 'root',
                'MAX_PROCESSORS': 1,
                'PROCESSORS_PER_NODE': 1,
            },
        },
    },
    {
        'JOBS': {
            'SIM': {
                'PLATFORM': _PLATFORM_NAME,
                'RUNNING': 'chunk',
                'SCRIPT': 'echo "0"',
            },
            'SIM_2': {
                'PLATFORM': _PLATFORM_NAME,
                'RUNNING': 'chunk',
                'SCRIPT': 'echo "0"',
                'DEPENDENCIES': 'SIM',
            },
        },
        'PLATFORMS': {
            _PLATFORM_NAME: {
                'ADD_PROJECT_TO_HOST': False,
                'HOST': '127.0.0.1',
                'MAX_WALLCLOCK': '00:03',
                'PROJECT': 'group',
                'QUEUE': 'gp_debug',
                'SCRATCH_DIR': '/tmp/scratch/',
                'TEMP_DIR': '',
                'TYPE': 'slurm',
                'USER': 'root',
                'MAX_PROCESSORS': 1,
                'PROCESSORS_PER_NODE': 1,
            },
        },
    },
], ids=[
    'Simple Workflow',
    'Dependency Workflow',
])
def test_run_simple_workflow_slurm(
        autosubmit_exp: AutosubmitExperimentFixture,
        experiment_data: dict,
        slurm_server: 'DockerContainer'
):
    """Runs a simple Bash script using Slurm."""
    exp = autosubmit_exp('t001', experiment_data=experiment_data, include_jobs=True)
    _create_slurm_platform(exp.expid, exp.as_conf)

    exp.autosubmit._check_ownership_and_set_last_command(exp.as_conf, exp.expid, 'run')
    assert 0 == exp.autosubmit.run_experiment(exp.expid)


@pytest.mark.parametrize('experiment_data', [
    {
        'JOBS': {
            'SIM': {
                'DEPENDENCIES': {
                    'SIM-1': {}
                },
                'SCRIPT': 'echo "0"',
                'WALLCLOCK': '00:03',
                'RUNNING': 'chunk',
                'CHECK': 'on_submission',
                'PLATFORM': _PLATFORM_NAME,
            },
            'POST': {
                'DEPENDENCIES': {
                    'SIM',
                },
                'SCRIPT': 'echo "0"',
                'WALLCLOCK': '00:03',
                'RUNNING': 'chunk',
                'CHECK': 'on_submission',
                'PLATFORM': _PLATFORM_NAME,
            },
            'TA': {
                'DEPENDENCIES': {
                    'SIM',
                    'POST',
                },
                'SCRIPT': 'echo "0"',
                'WALLCLOCK': '00:03',
                'RUNNING': 'once',
                'CHECK': 'on_submission',
                'PLATFORM': _PLATFORM_NAME,
            },
        },
        'PLATFORMS': {
            _PLATFORM_NAME: {
                'ADD_PROJECT_TO_HOST': False,
                'HOST': '127.0.0.1',
                'MAX_WALLCLOCK': '00:03',
                'PROJECT': 'group',
                'QUEUE': 'gp_debug',
                'SCRATCH_DIR': '/tmp/scratch/',
                'TEMP_DIR': '',
                'TYPE': 'slurm',
                'USER': 'root',
                'MAX_PROCESSORS': 1,
                'PROCESSORS_PER_NODE': 1,
            },
        },
        'WRAPPERS': {
            'WRAPPER': {
                'TYPE': 'vertical',
                'JOBS_IN_WRAPPER': 'SIM',
                'RETRIALS': 0,
            }
        },
    },
    {
        'JOBS': {
            'SIMV': {
                'DEPENDENCIES': {
                    'SIMV-1': {}
                },
                'SCRIPT': 'echo "0"',
                'WALLCLOCK': '00:03',
                'RUNNING': 'chunk',
                'CHECK': 'on_submission',
                'RETRIALS': 1,
                'PLATFORM': _PLATFORM_NAME,
            },
        },
        'PLATFORMS': {
            _PLATFORM_NAME: {
                'ADD_PROJECT_TO_HOST': False,
                'HOST': '127.0.0.1',
                'MAX_WALLCLOCK': '00:03',
                'PROJECT': 'group',
                'QUEUE': 'gp_debug',
                'SCRATCH_DIR': '/tmp/scratch/',
                'TEMP_DIR': '',
                'TYPE': 'slurm',
                'USER': 'root',
                'MAX_PROCESSORS': 1,
                'PROCESSORS_PER_NODE': 1,
            },
        },
        'WRAPPERS': {
            'WRAPPERV': {
                'TYPE': 'vertical',
                'JOBS_IN_WRAPPER': 'SIMV',
                'RETRIALS': 0,
            },
        },
    },
    {
        'JOBS': {
            'SIMH': {
                'DEPENDENCIES': {
                    'SIMH-1': {}
                },
                'SCRIPT': 'echo "0"',
                'WALLCLOCK': '00:03',
                'RUNNING': 'chunk',
                'CHECK': 'on_submission',
                'RETRIALS': 1,
                'PLATFORM': _PLATFORM_NAME,
            },
        },
        'PLATFORMS': {
            _PLATFORM_NAME: {
                'ADD_PROJECT_TO_HOST': False,
                'HOST': '127.0.0.1',
                'MAX_WALLCLOCK': '00:03',
                'PROJECT': 'group',
                'QUEUE': 'gp_debug',
                'SCRATCH_DIR': '/tmp/scratch/',
                'TEMP_DIR': '',
                'TYPE': 'slurm',
                'USER': 'root',
                'MAX_PROCESSORS': 1,
                'PROCESSORS_PER_NODE': 1,
            },
        },
        'WRAPPERS': {
            'WRAPPERH': {
                'TYPE': 'horizontal',
                'JOBS_IN_WRAPPER': 'SIMH',
                'RETRIALS': 0,
            },
        },
    },
    {
        'JOBS': {
            'SIMHV': {
                'DEPENDENCIES': {
                    'SIMHV-1': {}
                },
                'SCRIPT': 'echo "0"',
                'WALLCLOCK': '00:03',
                'RUNNING': 'chunk',
                'CHECK': 'on_submission',
                'RETRIALS': 1,
                'PLATFORM': _PLATFORM_NAME,
            },
        },
        'PLATFORMS': {
            _PLATFORM_NAME: {
                'ADD_PROJECT_TO_HOST': False,
                'HOST': '127.0.0.1',
                'MAX_WALLCLOCK': '00:03',
                'PROJECT': 'group',
                'QUEUE': 'gp_debug',
                'SCRATCH_DIR': '/tmp/scratch/',
                'TEMP_DIR': '',
                'TYPE': 'slurm',
                'USER': 'root',
                'MAX_PROCESSORS': 1,
                'PROCESSORS_PER_NODE': 1,
            },
        },
        'WRAPPERS': {
            'WRAPPERHV': {
                'TYPE': 'horizontal-vertical',
                'JOBS_IN_WRAPPER': 'SIMHV',
                'RETRIALS': 0,
            },
        },
    },
    {
        'JOBS': {
            'SIMVH': {
                'DEPENDENCIES': {
                    'SIMVH-1': {},
                },
                'SCRIPT': 'echo "0"',
                'WALLCLOCK': '00:03',
                'RUNNING': 'chunk',
                'CHECK': 'on_submission',
                'RETRIALS': 1,
                'PLATFORM': _PLATFORM_NAME,
            },
        },
        'PLATFORMS': {
            _PLATFORM_NAME: {
                'ADD_PROJECT_TO_HOST': False,
                'HOST': '127.0.0.1',
                'MAX_WALLCLOCK': '00:03',
                'PROJECT': 'group',
                'QUEUE': 'gp_debug',
                'SCRATCH_DIR': '/tmp/scratch/',
                'TEMP_DIR': '',
                'TYPE': 'slurm',
                'USER': 'root',
                'MAX_PROCESSORS': 1,
                'PROCESSORS_PER_NODE': 1,
            },
        },
        'WRAPPERS': {
            'WRAPPERVH': {
                'TYPE': 'vertical-horizontal',
                'JOBS_IN_WRAPPER': 'SIMVH',
                'RETRIALS': 0,
            },
        },
    },
], ids=[
    'Vertical Wrapper Workflow',
    'Wrapper Vertical',
    'Wrapper Horizontal',
    'Wrapper Horizontal-vertical',
    'Wrapper Vertical-horizontal',
])
@pytest.mark.docker
@pytest.mark.slurm
def test_run_all_wrappers_workflow_slurm(experiment_data: dict, autosubmit_exp: 'AutosubmitExperimentFixture',
                                         slurm_server: 'DockerContainer'):
    """Runs a simple Bash script using Slurm."""
    exp = autosubmit_exp(_EXPID, experiment_data=experiment_data, wrapper=True)
    _create_slurm_platform(exp.expid, exp.as_conf)

    exp.as_conf.experiment_data = {
        'EXPERIMENT': {
            'DATELIST': '20000101',
            'MEMBERS': 'fc0 fc1',
            'CHUNKSIZEUNIT': 'day',
            'CHUNKSIZE': 1,
            'NUMCHUNKS': '2',
            'CHUNKINI': '',
            'CALENDAR': 'standard',
        }
    }

    exp.autosubmit._check_ownership_and_set_last_command(exp.as_conf, exp.expid, 'run')
    assert 0 == exp.autosubmit.run_experiment(exp.expid)


@pytest.mark.parametrize('experiment_data', [
    {
        'JOBS': {
            'LOCAL_SETUP': {
                'SCRIPT': 'sleep 0',
                'RUNNING': 'once',
                'NOTIFY_ON': 'COMPLETED',
                'PLATFORM': _PLATFORM_NAME,
            },
            'LOCAL_SEND_SOURCE': {
                'SCRIPT': 'sleep 0',
                'PLATFORM': _PLATFORM_NAME,
                'DEPENDENCIES': 'LOCAL_SETUP',
                'RUNNING': 'once',
                'NOTIFY_ON': 'FAILED',
            },
            'LOCAL_SEND_STATIC': {
                'SCRIPT': 'sleep 0',
                'PLATFORM': _PLATFORM_NAME,
                'DEPENDENCIES': 'LOCAL_SETUP',
                'RUNNING': 'once',
                'NOTIFY_ON': 'FAILED',
            },
            'REMOTE_COMPILE': {
                'SCRIPT': 'sleep 0',
                'DEPENDENCIES': 'LOCAL_SEND_SOURCE',
                'RUNNING': 'once',
                'PROCESSORS': '1',
                'WALLCLOCK': '00:01',
                'NOTIFY_ON': 'COMPLETED',
            },
            'SIM': {
                'SCRIPT': 'sleep 0',
                'DEPENDENCIES': {
                    'LOCAL_SEND_STATIC': {},
                    'REMOTE_COMPILE': {},
                    'SIM-1': {},
                    'DA-1': {},
                },
                'RUNNING': 'once',
                'PROCESSORS': '1',
                'WALLCLOCK': '00:01',
                'NOTIFY_ON': 'FAILED',
                'PLATFORM': _PLATFORM_NAME,
            },
            'LOCAL_SEND_INITIAL_DA': {
                'SCRIPT': 'sleep 0',
                'PLATFORM': _PLATFORM_NAME,
                'DEPENDENCIES': 'LOCAL_SETUP LOCAL_SEND_INITIAL_DA-1',
                'RUNNING': 'chunk',
                'SYNCHRONIZE': 'member',
                'DELAY': '0',
            },
            'COMPILE_DA': {
                'SCRIPT': 'sleep 0',
                'DEPENDENCIES': 'LOCAL_SEND_SOURCE',
                'RUNNING': 'once',
                'WALLCLOCK': '00:01',
                'NOTIFY_ON': 'FAILED',
            },
            'DA': {
                'SCRIPT': 'sleep 0',
                'DEPENDENCIES': {
                    'SIM': {},
                    'LOCAL_SEND_INITIAL_DA': {
                        'CHUNKS_TO': 'all',
                        'DATES_TO': 'all',
                        'MEMBERS_TO': 'all',
                    },
                    'COMPILE_DA': {},
                    'DA': {
                        'DATES_FROM': {
                            '20120201': {
                                'CHUNKS_FROM': {
                                    '1': {
                                        'DATES_TO': '20120101',
                                    },
                                },
                            },
                        },
                    },
                },
                'RUNNING': 'chunk',
                'SYNCHRONIZE': 'member',
                'DELAY': '0',
                'WALLCLOCK': '00:01',
                'PROCESSORS': '1',
                'NOTIFY_ON': 'FAILED',
                'PLATFORM': _PLATFORM_NAME,
            },
        },
        'PLATFORMS': {
            _PLATFORM_NAME: {
                'ADD_PROJECT_TO_HOST': False,
                'HOST': '127.0.0.1',
                'MAX_WALLCLOCK': '00:03',
                'PROJECT': 'group',
                'QUEUE': 'gp_debug',
                'SCRATCH_DIR': '/tmp/scratch/',
                'TEMP_DIR': '',
                'TYPE': 'slurm',
                'USER': 'root',
                'MAX_PROCESSORS': 1,
                'PROCESSORS_PER_NODE': 1,
            },
        },
        'WRAPPERS': {
            'WRAPPER_SIMDA': {
                'TYPE': 'vertical-horizontal',
                'JOBS_IN_WRAPPER': 'SIM DA',
                'RETRIALS': '0',
            }
        },
    },
    {
        'JOBS': {
            'LOCAL_SETUP': {
                'SCRIPT': 'sleep 0',
                'RUNNING': 'once',
                'WALLCLOCK': '00:01',
                'NOTIFY_ON': 'COMPLETED',
                'PLATFORM': _PLATFORM_NAME,
            },
            'LOCAL_SEND_SOURCE': {
                'SCRIPT': 'sleep 0',
                'DEPENDENCIES': 'LOCAL_SETUP',
                'RUNNING': 'once',
                'WALLCLOCK': '00:01',
                'NOTIFY_ON': 'FAILED',
                'PLATFORM': _PLATFORM_NAME,
            },
            'LOCAL_SEND_STATIC': {
                'SCRIPT': 'sleep 0',
                'DEPENDENCIES': 'LOCAL_SETUP',
                'RUNNING': 'once',
                'WALLCLOCK': '00:01',
                'NOTIFY_ON': 'FAILED',
                'PLATFORM': _PLATFORM_NAME,
            },
            'REMOTE_COMPILE': {
                'SCRIPT': 'sleep 0',
                'DEPENDENCIES': 'LOCAL_SEND_SOURCE',
                'RUNNING': 'once',
                'PROCESSORS': '1',
                'WALLCLOCK': '00:01',
                'NOTIFY_ON': 'COMPLETED',
            },
            'SIM': {
                'SCRIPT': 'sleep 0',
                'DEPENDENCIES': {
                    'LOCAL_SEND_STATIC': {},
                    'REMOTE_COMPILE': {},
                    'SIM-1': {},
                    'DA-1': {},
                },
                'RUNNING': 'once',
                'PROCESSORS': '1',
                'WALLCLOCK': '00:01',
                'NOTIFY_ON': 'FAILED',
                'PLATFORM': _PLATFORM_NAME,
            },
            'LOCAL_SEND_INITIAL_DA': {
                'SCRIPT': 'sleep 0',
                'DEPENDENCIES': 'LOCAL_SETUP LOCAL_SEND_INITIAL_DA-1',
                'RUNNING': 'chunk',
                'WALLCLOCK': '00:01',
                'SYNCHRONIZE': 'member',
                'DELAY': '0',
                'PLATFORM': _PLATFORM_NAME,
            },
            'COMPILE_DA': {
                'SCRIPT': 'sleep 0',
                'DEPENDENCIES': 'LOCAL_SEND_SOURCE',
                'RUNNING': 'once',
                'WALLCLOCK': '00:01',
                'NOTIFY_ON': 'FAILED',
            },
            'DA': {
                'SCRIPT': 'sleep 0',
                'DEPENDENCIES': {
                    'SIM': {},
                    'LOCAL_SEND_INITIAL_DA': {
                        'CHUNKS_TO': 'all',
                        'DATES_TO': 'all',
                        'MEMBERS_TO': 'all',
                    },
                    'COMPILE_DA': {},
                    'DA': {
                        'DATES_FROM': {
                            '20120201': {
                                'CHUNKS_FROM': {
                                    '1': {
                                        'DATES_TO': '20120101',
                                        'CHUNKS_TO': '1',
                                    },
                                },
                            },
                        },
                    },
                },
                'RUNNING': 'chunk',
                'SYNCHRONIZE': 'member',
                'DELAY': '0',
                'WALLCLOCK': '00:01',
                'PROCESSORS': '1',
                'NOTIFY_ON': 'FAILED',
                'PLATFORM': _PLATFORM_NAME,
            },
        },
        'PLATFORMS': {
            _PLATFORM_NAME: {
                'ADD_PROJECT_TO_HOST': False,
                'HOST': '127.0.0.1',
                'MAX_WALLCLOCK': '00:03',
                'PROJECT': 'group',
                'QUEUE': 'gp_debug',
                'SCRATCH_DIR': '/tmp/scratch/',
                'TEMP_DIR': '',
                'TYPE': 'slurm',
                'USER': 'root',
                'MAX_PROCESSORS': 1,
                'PROCESSORS_PER_NODE': 1,
            },
        },
        'WRAPPERS': {
            'WRAPPER_SIMDA': {
                'TYPE': 'horizontal-vertical',
                'JOBS_IN_WRAPPER': 'SIM&DA',
                'RETRIALS': '0',
            }
        },
    }
], ids=[
    'Complex Wrapper vertical-horizontal',
    'Complex Wrapper horizontal-vertical',
])
@pytest.mark.docker
@pytest.mark.slurm
def test_run_all_wrappers_workflow_slurm_complex(experiment_data: dict, autosubmit_exp: 'AutosubmitExperimentFixture',
                                                 slurm_server: 'DockerContainer'):
    """Runs a simple Bash script using Slurm."""

    exp = autosubmit_exp('t002', experiment_data=experiment_data, wrapper=True)
    _create_slurm_platform(exp.expid, exp.as_conf)

    exp.as_conf.experiment_data = {
        'EXPERIMENT': {
            'DATELIST': '20000101',
            'MEMBERS': 'fc0 fc1',
            'CHUNKSIZEUNIT': 'day',
            'CHUNKSIZE': 1,
            'NUMCHUNKS': '2',
            'CHUNKINI': '',
            'CALENDAR': 'standard',
        }
    }

    exp.autosubmit._check_ownership_and_set_last_command(exp.as_conf, exp.expid, 'run')
    assert 0 == exp.autosubmit.run_experiment(exp.expid)


@pytest.mark.docker
@pytest.mark.slurm
def test_check_remote_permissions(autosubmit_exp, slurm_server: 'DockerContainer'):
    exp = autosubmit_exp(_EXPID, experiment_data={
        'JOBS': {
            'SIM_V_H': {
                'DEPENDENCIES': {
                    'SIM_V_H-1': {},
                },
                'SCRIPT': 'sleep 0',
                'WALLCLOCK': '00:03',
                'RUNNING': 'chunk',
                'CHECK': 'on_submission',
                'RETRIALS': 1,
                'PLATFORM': _PLATFORM_NAME,
            },
        },
        'PLATFORMS': {
            _PLATFORM_NAME: {
                'ADD_PROJECT_TO_HOST': False,
                'HOST': '127.0.0.1',
                'MAX_WALLCLOCK': '00:03',
                'PROJECT': 'group',
                'QUEUE': 'gp_debug',
                'SCRATCH_DIR': '/tmp/scratch/',
                'TEMP_DIR': '',
                'TYPE': 'slurm',
                'USER': 'root',
                'MAX_PROCESSORS': 10,
                'PROCESSORS_PER_NODE': 10,
            },
        }
    }, wrapper=True)
    submitter = ParamikoSubmitter(as_conf=exp.as_conf)

    slurm_platform: SlurmPlatform = submitter.platforms[_PLATFORM_NAME]

    slurm_platform.connect(as_conf=exp.as_conf)

    assert slurm_platform.check_remote_permissions()

    slurm_platform.close_connection()
    assert not slurm_platform.check_remote_permissions()


@pytest.mark.docker
@pytest.mark.slurm
@pytest.mark.parametrize(
    "experiment_data",
    [
        {
            "JOBS": {
                "SIM": {
                    "PLATFORM": _PLATFORM_NAME,
                    "RUNNING": "once",
                    "SCRIPT": 'echo "This is job ${SLURM_JOB_ID} EOM"',
                },
            },
            "PLATFORMS": {
                _PLATFORM_NAME: {
                    "ADD_PROJECT_TO_HOST": False,
                    "HOST": "127.0.0.1",
                    "MAX_WALLCLOCK": "00:03",
                    "PROJECT": "group",
                    "QUEUE": "gp_debug",
                    "SCRATCH_DIR": "/tmp/scratch/",
                    "TEMP_DIR": "",
                    "TYPE": "slurm",
                    "USER": "root",
                    "COMPRESS_REMOTE_LOGS": True,
                },
            },
        },
        {
            "JOBS": {
                "SIM": {
                    "PLATFORM": _PLATFORM_NAME,
                    "RUNNING": "once",
                    "SCRIPT": 'echo "This is job ${SLURM_JOB_ID} EOM"',
                },
            },
            "PLATFORMS": {
                _PLATFORM_NAME: {
                    "ADD_PROJECT_TO_HOST": False,
                    "HOST": "127.0.0.1",
                    "MAX_WALLCLOCK": "00:03",
                    "PROJECT": "group",
                    "QUEUE": "gp_debug",
                    "SCRATCH_DIR": "/tmp/scratch/",
                    "TEMP_DIR": "",
                    "TYPE": "PS",
                    "USER": "root",
                    "COMPRESS_REMOTE_LOGS": True,
                    "REMOTE_LOGS_COMPRESS_TYPE": "xz",
                },
            },
        },
        {
            "JOBS": {
                "SIM": {
                    "PLATFORM": _PLATFORM_NAME,
                    "RUNNING": "once",
                    "SCRIPT": 'echo "This is job ${SLURM_JOB_ID} EOM"',
                },
            },
            "PLATFORMS": {
                _PLATFORM_NAME: {
                    "ADD_PROJECT_TO_HOST": False,
                    "HOST": "127.0.0.1",
                    "MAX_WALLCLOCK": "00:03",
                    "PROJECT": "group",
                    "QUEUE": "gp_debug",
                    "SCRATCH_DIR": "/tmp/scratch/",
                    "TEMP_DIR": "",
                    "TYPE": "slurm",
                    "USER": "root",
                    "COMPRESS_REMOTE_LOGS": True,
                    "PROCESSORS_PER_NODE": 1,
                    "MAX_PROCESSORS": 1,
                },
            },
            "WRAPPERS": {
                "WRAPPER": {
                    "TYPE": "vertical",
                    "JOBS_IN_WRAPPER": "SIM",
                }
            },
        },
        {
            "JOBS": {
                "SIM": {
                    "PLATFORM": _PLATFORM_NAME,
                    "RUNNING": "once",
                    "SCRIPT": 'd_echo "FAIL"',
                    "RETRIALS": 2,
                },
            },
            "PLATFORMS": {
                _PLATFORM_NAME: {
                    "ADD_PROJECT_TO_HOST": False,
                    "HOST": "127.0.0.1",
                    "MAX_WALLCLOCK": "00:03",
                    "PROJECT": "group",
                    "QUEUE": "gp_debug",
                    "SCRATCH_DIR": "/tmp/scratch/",
                    "TEMP_DIR": "",
                    "TYPE": "slurm",
                    "USER": "root",
                    "COMPRESS_REMOTE_LOGS": True,
                    "PROCESSORS_PER_NODE": 1,
                    "MAX_PROCESSORS": 1,
                },
            },
            "WRAPPERS": {
                "WRAPPER": {
                    "TYPE": "vertical",
                    "JOBS_IN_WRAPPER": "SIM",
                    "POLICY": "flexible",
                }
            },
        }
    ],
    ids=[
        "Compress logs with default gzip",
        "Compress logs with xz in PS platform",
        "Compress logs with gzip and vertical wrapper",
        "Compress logs with gzip, vertical wrappers and retrials",
    ],
)
def test_simple_workflow_compress_logs_slurm(
    autosubmit_exp: "AutosubmitExperimentFixture",
    experiment_data: dict,
    slurm_server: "DockerContainer",
):
    """Test compressing remote logs in a simple workflow using Slurm."""
    with_wrapper = "WRAPPERS" in experiment_data

    exp = autosubmit_exp(_EXPID, experiment_data=experiment_data, wrapper=with_wrapper, include_jobs=False)
    _create_slurm_platform(exp.expid, exp.as_conf)

    exp.autosubmit._check_ownership_and_set_last_command(exp.as_conf, exp.expid, "run")
    exp.autosubmit.run_experiment(exp.expid)

    # Check if the log files are compressed
    logs_dir = Path(exp.as_conf.basic_config.LOCAL_ROOT_DIR).joinpath(
        exp.expid, exp.as_conf.basic_config.LOCAL_TMP_DIR, f"LOG_{exp.expid}"
    )
    compression_type = (
        experiment_data.get("PLATFORMS", {})
        .get(_PLATFORM_NAME, {})
        .get("REMOTE_LOGS_COMPRESS_TYPE", "gzip")
    )

    # Get all files in the logs directory
    files = [f for f in Path(logs_dir).glob("*")]

    assert len(files) > 0, f"No log files found in {logs_dir}"

    # Get job_data
    exp_history = ExperimentHistory(
        exp.expid,
        exp.as_conf.basic_config.JOBDATA_DIR,
        exp.as_conf.basic_config.HISTORICAL_LOG_DIR,
    )
    last_job_data = exp_history.manager.get_all_last_job_data_dcs()
    assert len(last_job_data) > 0, "No job data found after running the experiment."

    logs_filenames: list[str] = []
    for job in last_job_data:
        logs_filenames.extend([job.out, job.err])

    if compression_type == "xz":
        _val_fn = is_xz_file
        assert any(is_xz_file(str(f)) for f in files), (
            "No compressed xz log files found."
        )
        assert all(log_filename.endswith(".xz") for log_filename in logs_filenames)
    else:
        _val_fn = is_gzip_file
        assert any(is_gzip_file(str(f)) for f in files), (
            "No compressed gzip log files found."
        )
        assert all(log_filename.endswith(".gz") for log_filename in logs_filenames)

    for log_filename in logs_filenames:
        log_path = logs_dir.joinpath(log_filename)
        assert log_path.exists(), f"Log file {log_path} does not exist."
        assert _val_fn(str(log_path)), (
            f"Log file {log_path} is not compressed as expected."
        )


@pytest.mark.docker
@pytest.mark.slurm
@pytest.mark.parametrize(
    "experiment_data",
    [
        {
            "JOBS": {
                "SIM": {
                    "PLATFORM": _PLATFORM_NAME,
                    "RUNNING": "once",
                    "SCRIPT": 'echo "This is job ${SLURM_JOB_ID} EOM"',
                },
            },
            "PLATFORMS": {
                _PLATFORM_NAME: {
                    "ADD_PROJECT_TO_HOST": False,
                    "HOST": "127.0.0.1",
                    "MAX_WALLCLOCK": "00:03",
                    "PROJECT": "group",
                    "QUEUE": "gp_debug",
                    "SCRATCH_DIR": "/tmp/scratch/",
                    "TEMP_DIR": "",
                    "TYPE": "slurm",
                    "USER": "root",
                    "COMPRESS_REMOTE_LOGS": True,
                },
            },
        },
    ],
    ids=[
        "Default compress logs with missing compression tool",
    ],
)
def test_compress_log_missing_tool(
    experiment_data: dict,
    autosubmit_exp: "AutosubmitExperimentFixture",
    slurm_server: "DockerContainer",
    mocker,
):
    exp = autosubmit_exp(_EXPID, experiment_data=experiment_data, include_jobs=False)
    _create_slurm_platform(exp.expid, exp.as_conf)

    exp.autosubmit._check_ownership_and_set_last_command(exp.as_conf, exp.expid, "run")

    # Mock the compress_file method to simulate missing compression tool
    mocker.patch(
        "autosubmit.platforms.paramiko_platform.ParamikoPlatform.compress_file",
        return_value=None,
    )
    exp.autosubmit.run_experiment(exp.expid)

    # Check if the log files are compressed
    logs_dir = Path(exp.as_conf.basic_config.LOCAL_ROOT_DIR).joinpath(
        exp.expid, exp.as_conf.basic_config.LOCAL_TMP_DIR, f"LOG_{exp.expid}"
    )

    # Get all files in the logs directory
    files = [f for f in Path(logs_dir).glob("*")]
    assert len(files) > 0, f"No log files found in {logs_dir}"

    # Get job_data
    exp_history = ExperimentHistory(
        exp.expid,
        exp.as_conf.basic_config.JOBDATA_DIR,
        exp.as_conf.basic_config.HISTORICAL_LOG_DIR,
    )
    last_job_data = exp_history.manager.get_all_last_job_data_dcs()
    assert len(last_job_data) > 0, "No job data found after running the experiment."

    logs_filenames: list[str] = []
    for job in last_job_data:
        logs_filenames.extend([job.out, job.err])

    # None of the log files should be compressed
    for log_filename in logs_filenames:
        assert not log_filename.endswith(".gz") and not log_filename.endswith(".xz"), (
            f"Log file {log_filename} should not have a compressed extension."
        )

        log_path = logs_dir.joinpath(log_filename)
        assert log_path.exists(), f"Log file {log_path} does not exist."
        assert not is_gzip_file(str(log_path)) and not is_xz_file(str(log_path)), (
            f"Log file {log_path} should not be compressed."
        )


@pytest.mark.docker
@pytest.mark.slurm
@pytest.mark.parametrize(
    "experiment_data",
    [
        {
            "JOBS": {
                "SIM": {
                    "PLATFORM": _PLATFORM_NAME,
                    "RUNNING": "once",
                    "SCRIPT": 'echo "This is job ${SLURM_JOB_ID} EOM"',
                },
            },
            "PLATFORMS": {
                _PLATFORM_NAME: {
                    "ADD_PROJECT_TO_HOST": False,
                    "HOST": "127.0.0.1",
                    "MAX_WALLCLOCK": "00:03",
                    "PROJECT": "group",
                    "QUEUE": "gp_debug",
                    "SCRATCH_DIR": "/tmp/scratch/",
                    "TEMP_DIR": "",
                    "TYPE": "slurm",
                    "USER": "root",
                    "COMPRESS_REMOTE_LOGS": True,
                },
            },
        },
    ],
    ids=[
        "Default compress logs with missing compression tool",
    ],
)
def test_compress_log_fail_command(
    experiment_data: dict,
    autosubmit_exp: "AutosubmitExperimentFixture",
    slurm_server: "DockerContainer",
    mocker,
):
    exp = autosubmit_exp(_EXPID, experiment_data=experiment_data)
    _create_slurm_platform(exp.expid, exp.as_conf)

    mocker.patch(
        "autosubmit.platforms.paramiko_platform.ParamikoPlatform.send_command",
        side_effect=Exception("cmd not found"),
    )

    result = exp.platform.compress_file("/some_log_file.log")
    assert result is None


@pytest.mark.docker
@pytest.mark.slurm
@pytest.mark.parametrize(
    "experiment_data",
    [
        {
            "JOBS": {
                "SIM": {
                    "PLATFORM": _PLATFORM_NAME,
                    "RUNNING": "once",
                    "SCRIPT": 'echo "This is job ${SLURM_JOB_ID} EOM"',
                },
            },
            "PLATFORMS": {
                _PLATFORM_NAME: {
                    "ADD_PROJECT_TO_HOST": False,
                    "HOST": "127.0.0.1",
                    "MAX_WALLCLOCK": "00:03",
                    "PROJECT": "group",
                    "QUEUE": "gp_debug",
                    "SCRATCH_DIR": "/tmp/scratch/",
                    "TEMP_DIR": "",
                    "TYPE": "slurm",
                    "USER": "root",
                    "REMOVE_LOG_FILES_ON_TRANSFER": True,
                },
            },
        },
        {
            "JOBS": {
                "SIM": {
                    "PLATFORM": _PLATFORM_NAME,
                    "RUNNING": "once",
                    "SCRIPT": 'echo "This is job ${SLURM_JOB_ID} EOM"',
                },
            },
            "PLATFORMS": {
                _PLATFORM_NAME: {
                    "ADD_PROJECT_TO_HOST": False,
                    "HOST": "127.0.0.1",
                    "MAX_WALLCLOCK": "00:03",
                    "PROJECT": "group",
                    "QUEUE": "gp_debug",
                    "SCRATCH_DIR": "/tmp/scratch/",
                    "TEMP_DIR": "",
                    "TYPE": "slurm",
                    "USER": "root",
                    "REMOVE_LOG_FILES_ON_TRANSFER": True,
                    "COMPRESS_REMOTE_LOGS": True,
                },
            },
        },
    ],
    ids=[
        "Remove files on transfer",
        "Remove files on transfer with compressed logs",
    ],
)
def test_remove_files_on_transfer_slurm(
    experiment_data: dict,
    autosubmit_exp: "AutosubmitExperimentFixture",
    slurm_server: "DockerContainer",
):
    _NEW_EXPID = "t444"  # Use a different EXPID to avoid conflicts
    exp = autosubmit_exp(_NEW_EXPID, experiment_data=experiment_data)
    _create_slurm_platform(exp.expid, exp.as_conf)

    exp.autosubmit._check_ownership_and_set_last_command(exp.as_conf, exp.expid, "run")
    exp.autosubmit.run_experiment(exp.expid)

    remote_logs_dir = Path(
        experiment_data["PLATFORMS"][_PLATFORM_NAME]["SCRATCH_DIR"],
        experiment_data["PLATFORMS"][_PLATFORM_NAME]["PROJECT"],
        experiment_data["PLATFORMS"][_PLATFORM_NAME]["USER"],
        exp.expid,
        f"LOG_{exp.expid}",
    )

    result = slurm_server.exec(f"ls {remote_logs_dir}")
    filenames = result.output.decode().strip().split("\n")

    for filename in filenames:
        assert not bool(re.match(r".*\.(out|err)(\.(xz|gz))?$", filename))


def test_check_if_packages_are_ready_to_build(autosubmit_exp):
    exp = autosubmit_exp('a000', experiment_data={})
    platform_config = {
        "LOCAL_ROOT_DIR": exp.as_conf.basic_config.LOCAL_ROOT_DIR,
        "LOCAL_TMP_DIR": str(exp.as_conf.basic_config.LOCAL_ROOT_DIR+'exp_tmp_dir'),
        "LOCAL_ASLOG_DIR": str(exp.as_conf.basic_config.LOCAL_ROOT_DIR+'aslogs_dir')
    }
    platform = SlurmPlatform('a000', "wrappers_test", platform_config)

    job_list = JobList('a000', exp.as_conf, YAMLParserFactory(), JobListPersistencePkl())
    for i in range(3):
        job = Job(f"job{i}", i, Status.READY, 0)
        job.section = f"SECTION{i}"
        job.platform = platform
        job_list._job_list.append(job)

    packager = JobPackager(exp.as_conf, platform, job_list)
    packager.wallclock = "01:00"
    packager.het = {
        'HETSIZE': {'CURRENT_QUEUE': ''},
        'CURRENT_QUEUE': '',
        'NODES': [2],
        'PARTITION': [''],
        'CURRENT_PROJ': '',
        'EXCLUSIVE': 'false',
        'MEMORY': '',
        'MEMORY_PER_TASK': 2,
        'NUMTHREADS': '',
        'RESERVATION': '',
        'CUSTOM_DIRECTIVES': '',
        'TASKS': ''
    }

    job_result, check = packager.check_if_packages_are_ready_to_build()
    assert check and len(job_result) == 3


@pytest.mark.docker
@pytest.mark.slurm
def test_run_bug_save_wrapper_crashes(
        autosubmit_exp: 'AutosubmitExperimentFixture',
        mocker,
        slurm_server: 'DockerContainer'
):
    """In issue 2463, JIRA 794 of DestinE, users reported getting an exception
    ``'list' object has no attribute 'status'``.

    It appears to be caused by a combination of states of database and pickle,
    and there could be more than one possible scenario to trigger this issue.

    We identified one, where ``JobList.save_wrappers`` crashed before the
    job packages databases were populated. The job list persisted to disk as
    pickle was saved with its jobs ``SUBMITTED``, which then caused a subsequent
    ``run`` command to trigger this exception (note, that the run is executed
    without a ``recovery``, which is not quite what happened in other cases).

    This test simulates that scenario. It was written using ``master`` of
    4.1.15+, then applied to the pull request #2474. The issue of accessing
    ``status`` of a Python ``list`` object has also been fixed in that pull
    request -- the fix was postponed to see if we could locate the root
    cause, even though this may not be the root cause.

    Ref:

    * https://github.com/BSC-ES/autosubmit/issues/2463
    * https://jira.eduuni.fi/browse/CSCDESTINCLIMADT-794
    """
    exp = autosubmit_exp(_EXPID, experiment_data={
        'JOBS': {
            'SIM': {
                'PLATFORM': 'LOCAL_DOCKER',
                'RUNNING': 'chunk',
                'SCRIPT': dedent('''\
                # Fails on the second and third chunks
                CHUNK="%CHUNK%"
                if [ "$CHUNK" -eq 1 ]
                then
                    echo "OK!"
                else
                    echo "Uh oh"
                    crashit!
                fi
                '''),
                'DEPENDENCIES': {
                    'SIM-1': {}
                },
                'WALLCLOCK': '00:02',
                'RETRIALS': 5,
            }
        },
        'WRAPPERS': {
            'WRAPPER_V': {
                'TYPE': 'vertical',
                'JOBS_IN_WRAPPER': 'SIM',
                'RETRIALS': 1
            }
        },
        'PLATFORMS': {
            'LOCAL_DOCKER': {
                'ADD_PROJECT_TO_HOST': False,
                'HOST': '127.0.0.1',
                'MAX_WALLCLOCK': '00:03',
                'PROJECT': 'group',
                'QUEUE': 'gp_debug',
                'SCRATCH_DIR': '/tmp/scratch/',
                'TEMP_DIR': '',
                'TYPE': 'slurm',
                'USER': 'root',
                'MAX_PROCESSORS': 1,
                'PROCESSORS_PER_NODE': 1,
            }
        }
    })

    mocked_job_list_save_wrappers = mocker.patch.object(JobList, 'save_wrappers', side_effect=ValueError)

    with pytest.raises(ValueError):
        exp.autosubmit.run_experiment(expid=_EXPID)

    mocked_job_list_save_wrappers.reset_mock()

    # NOTE: On ``master`` before the fix (commit d635461f4ecac42985ba584e2cbfa65223ea2151),
    #       this fails instead of raising ``ValueError``, showing the same exception
    #       reported by users, ``AttributeError: 'list' object has no attribute 'status'``.
    with pytest.raises(ValueError):
        exp.autosubmit.run_experiment(expid=_EXPID)
