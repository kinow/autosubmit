from pathlib import Path
from typing import Any

from autosubmit.config.basicconfig import BasicConfig
from autosubmit.history.data_classes.job_data import JobData
from autosubmit.job.job_common import Status

import pytest
from autosubmit.log.log import AutosubmitCritical

from autosubmit.history.database_managers.experiment_history_db_manager import SqlAlchemyExperimentHistoryDbManager


@pytest.fixture(scope="function")
def as_exp(autosubmit_exp, general_data, experiment_data, jobs_data):
    config_data = general_data | experiment_data | jobs_data
    return autosubmit_exp(experiment_data=config_data, include_jobs=False, create=True)


@pytest.fixture(scope="function")
def submitter(as_exp):
    submitter = as_exp.autosubmit._get_submitter(as_exp.as_conf)
    submitter.load_platforms(as_exp.as_conf)
    return submitter


@pytest.fixture(scope="function")
def job_list(as_exp, submitter):
    return as_exp.autosubmit.load_job_list(
        as_exp.expid, as_exp.as_conf, new=False)


@pytest.fixture(scope="function")
def prepare_scratch(as_exp, tmp_path: Path, job_list, job_names_to_recover, slurm_server) -> Any:
    """Generates some completed and stat files in the scratch directory to simulate completed jobs.

    :param as_exp: The Autosubmit experiment object.
    :param tmp_path: The temporary path for the experiment.
    :param job_list: The job list object.
    :param job_names_to_recover: The list of job names to recover.
    :param slurm_server: The SLURM server container.
    :type as_exp: Any
    :type tmp_path: Path
    :type job_list: Any
    :type job_names_to_recover: Any
    :type slurm_server: Any
    """
    slurm_root = f"/tmp/scratch/group/root/{as_exp.expid}/"
    log_dir = Path(slurm_root) / f'LOG_{as_exp.expid}/'
    local_completed_dir = tmp_path / as_exp.expid / "tmp" / f'LOG_{as_exp.expid}/'
    slurm_server.exec(
        f'mkdir -p {log_dir}')  # combining this with the touch, makes the touch generates a folder instead of a file. I have no idea why.

    cmds = []
    for name in job_names_to_recover:
        if "LOCAL" in name:
            local_completed_dir.mkdir(parents=True, exist_ok=True)
            (local_completed_dir / f"{name}_COMPLETED").touch()
        else:
            cmds.append(f'touch {log_dir}/{name}_COMPLETED')
    full_cmd = " && ".join(cmds)
    slurm_server.exec(full_cmd)


@pytest.fixture(scope="function")
def job_names_to_recover(job_list):
    return [job.name for job in job_list.get_job_list() if job.split == 1 or job.split == 3]


@pytest.mark.parametrize("active_jobs,force", [
    (True, True),
    (True, False),
    (False, True),
    (False, False),
], ids=[
    "Active_jobs&Force == recover_all",
    "Active_jobs&No_Force == raise_error",
    "No_Active_jobs&Force == recover_all",
    "No_Active_jobs&No_Force == recover_all",
])
@pytest.mark.slurm
def test_online_recovery(as_exp, prepare_scratch, submitter, slurm_server, job_names_to_recover, active_jobs, force):
    """Test the recovery of an experiment.

    :param as_exp: The Autosubmit experiment object.
    :param prepare_scratch: Fixture to prepare the scratch directory.
    :type as_exp: Any
    :type prepare_scratch: Any
    """
    job_list_ = as_exp.autosubmit.load_job_list(
        as_exp.expid, as_exp.as_conf, new=False)
    db_manager = SqlAlchemyExperimentHistoryDbManager(as_exp.expid, BasicConfig.JOBDATA_DIR, f'job_data_{as_exp.expid}.db')
    db_manager.initialize()
    # Save fails if platform is not set ( in 4.2 this is not the case )
    submitter = as_exp.autosubmit._get_submitter(as_exp.as_conf)
    submitter.load_platforms(as_exp.as_conf)
    platforms = submitter.platforms

    for job in job_list_.get_job_list():
        if not job.platform:
            job.platform = platforms[job.platform_name]
        if job.name in job_names_to_recover:
            if active_jobs:
                job.status = Status.RUNNING
            else:
                job.status = Status.WAITING

    job_list_.save()

    if active_jobs and not force:
        with pytest.raises(AutosubmitCritical):
            as_exp.autosubmit.recovery(
                as_exp.expid,
                noplot=False,  # Just test that is called without errors
                save=True,
                all_jobs=True,
                hide=True,  # Just test that is called without errors
                group_by="date",  # Just test that is called without errors
                expand=[],
                expand_status=[],
                detail=True,
                force=force,
                offline=False
            )
    else:
        as_exp.autosubmit.recovery(
            as_exp.expid,
            noplot=False,
            save=True,
            all_jobs=True,
            hide=True,
            group_by="date",
            expand=[],
            expand_status=[],
            detail=True,
            force=force,
            offline=False
        )

        job_list_ = as_exp.autosubmit.load_job_list(
            as_exp.expid, as_exp.as_conf, new=False)

        completed_jobs = [job.name for job in job_list_.get_job_list() if job.status == Status.COMPLETED]

        for name in job_names_to_recover:
            # 2nd split is not completed, so the 3ยบ split was marked as COMPLETED ( file found) and then WAITING
            split_number = name.split('_')[-2]
            if split_number == "3":
                assert name not in completed_jobs
            else:
                assert name in completed_jobs


@pytest.mark.parametrize("active_jobs,force", [
    (True, True),
    (True, False),
    (False, True),
    (False, False),
], ids=[
    "Active_jobs&Force == recover_all",
    "Active_jobs&No_Force == raise_error",
    "No_Active_jobs&Force == recover_all",
    "No_Active_jobs&No_Force == recover_all",
])
def test_offline_recovery(as_exp, tmp_path, submitter, job_names_to_recover, active_jobs, force):
    try:
        job_names_to_recover = [name for name in job_names_to_recover if "LOCAL" not in name]
        as_exp.as_conf.set_last_as_command('recovery')

        db_manager = SqlAlchemyExperimentHistoryDbManager(as_exp.expid, BasicConfig.JOBDATA_DIR, f'job_data_{as_exp.expid}.db')

        db_manager.initialize()
        job_list_ = as_exp.autosubmit.load_job_list(
            as_exp.expid, as_exp.as_conf, new=False)

        submitter = as_exp.autosubmit._get_submitter(as_exp.as_conf)
        submitter.load_platforms(as_exp.as_conf)
        platforms = submitter.platforms

        for job in job_list_.get_job_list():
            if not job.platform:
                job.platform = platforms[job.platform_name]
            if job.name in job_names_to_recover:
                if active_jobs:
                    job.status = Status.RUNNING
                else:
                    job.status = Status.WAITING

            job_data_dc = JobData(_id=0,
                                  counter=0,
                                  job_name=job.name,
                                  submit=11111,
                                  status="COMPLETED",
                                  rowtype=0,
                                  ncpus=0,
                                  wallclock="00:01",
                                  qos="debug",
                                  date=job.date,
                                  member=job.member,
                                  section=job.section,
                                  chunk=job.chunk,
                                  platform=job.platform_name,
                                  job_id=job.id,
                                  children=None,
                                  run_id=1,
                                  workflow_commit=None)
            db_manager._insert_job_data(job_data_dc)
            job_data_dc = JobData(_id=0,
                                  counter=1,
                                  job_name=job.name,
                                  submit=11111,
                                  status="FAILED",
                                  rowtype=0,
                                  ncpus=0,
                                  wallclock="00:01",
                                  qos="debug",
                                  date=job.date,
                                  member=job.member,
                                  section=job.section,
                                  chunk=job.chunk,
                                  platform=job.platform_name,
                                  job_id=job.id,
                                  children=None,
                                  run_id=2,
                                  workflow_commit=None)
            db_manager._insert_job_data(job_data_dc)
            job_data_dc = JobData(_id=0,
                                  counter=2,
                                  job_name=job.name,
                                  submit=11111,
                                  status="COMPLETED",
                                  rowtype=0,
                                  ncpus=0,
                                  wallclock="00:01",
                                  qos="debug",
                                  date=job.date,
                                  member=job.member,
                                  section=job.section,
                                  chunk=job.chunk,
                                  platform=job.platform_name,
                                  job_id=job.id,
                                  children=None,
                                  run_id=3,
                                  workflow_commit=None)
            db_manager._insert_job_data(job_data_dc)
        job_list_.save()

        if active_jobs and not force:
            with pytest.raises(AutosubmitCritical):
                as_exp.autosubmit.recovery(
                    as_exp.expid,
                    noplot=False,
                    save=True,
                    all_jobs=True,
                    hide=True,
                    group_by="date",
                    expand=[],
                    expand_status=[],
                    detail=True,
                    force=force,
                    offline=True
                )
        else:
            as_exp.autosubmit.recovery(
                as_exp.expid,
                noplot=False,
                save=True,
                all_jobs=True,
                hide=True,
                group_by="date",
                expand=[],
                expand_status=[],
                detail=True,
                force=force,
                offline=True
            )
            job_list__ = as_exp.autosubmit.load_job_list(
                as_exp.expid, as_exp.as_conf, new=False)

            completed_jobs = [job.name for job in job_list__.get_job_list() if job.status == Status.COMPLETED]

            for name in job_names_to_recover:
                # 2nd split is not completed, so the 3ยบ split was marked as COMPLETED and then WAITING
                split_number = name.split('_')[-2]
                if split_number == "3":
                    assert name not in completed_jobs
                else:
                    assert name in completed_jobs

    except BaseException as e:  # TODO fix this test to work in parallel
        print(str(e))
        pytest.xfail("Offline recovery test is flaky, needs investigation. It always works when launched alone or with setstatus/recovery tests")
